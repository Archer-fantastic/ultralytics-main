# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import argparse
import os

from ultralytics import YOLO


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°."""
    parser = argparse.ArgumentParser(description="YOLO å®ä¾‹åˆ†å‰²è®­ç»ƒè„šæœ¬")
    # æ•°æ®é›†é…ç½®
    parser.add_argument(
        "--data",
        type=str,
        default=r"D:\Min\Projects\VSCodeProjects\dataset\instance_æ¼é‡‘å±_lxm\yolo_instance_dataset\dataset.yaml",
        help="æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆdataset.yamlï¼‰è·¯å¾„",
    )
    # æ¨¡å‹é…ç½®
    parser.add_argument(
        "--model",
        type=str,
        default=r"D:\Min\Projects\VSCodeProjects\ultralytics-main\weights\yolov8n-seg.pt",
        help="é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ yolov8n-seg.pt, yolov8s-seg.ptï¼‰",
    )
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--epochs", type=int, default=50, help="è®­ç»ƒè½®æ¬¡")
    parser.add_argument("--imgsz", type=int, default=640, help="è¾“å…¥å›¾ç‰‡å°ºå¯¸ï¼ˆéœ€ä¸º32çš„å€æ•°ï¼‰")
    parser.add_argument("--batch", type=int, default=16, help="æ‰¹æ¬¡å¤§å°ï¼ˆCPUè®­ç»ƒå¯å‡å°ï¼Œå¦‚8ï¼‰")
    parser.add_argument("--device", type=str, default="0", help="è®­ç»ƒè®¾å¤‡ï¼ˆcpu æˆ– 0,1... è¡¨ç¤ºGPUï¼‰")
    parser.add_argument("--lr0", type=float, default=0.01, help="åˆå§‹å­¦ä¹ ç‡")
    # è¾“å‡ºé…ç½®
    parser.add_argument(
        "--project",
        type=str,
        default=r"D:\Min\Projects\VSCodeProjects\ultralytics-main\train\runs\segment",
        help="è®­ç»ƒç»“æœä¿å­˜æ ¹ç›®å½•",
    )
    parser.add_argument("--name", type=str, default="train", help="æœ¬æ¬¡è®­ç»ƒæ–‡ä»¶å¤¹åç§°")
    return parser.parse_args()


def train_segmentation(args):
    """è®­ç»ƒYOLOå®ä¾‹åˆ†å‰²æ¨¡å‹."""
    # 1. åŠ è½½æ¨¡å‹ï¼ˆé¢„è®­ç»ƒåˆ†å‰²æ¨¡å‹ï¼‰
    model = YOLO(args.model)
    print(f"å·²åŠ è½½æ¨¡å‹: {args.model}")

    # 2. æ£€æŸ¥æ•°æ®é›†é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.data):
        raise FileNotFoundError(f"æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
    print(f"ä½¿ç”¨æ•°æ®é›†é…ç½®: {args.data}")

    # 3. å¼€å§‹è®­ç»ƒ
    print("å¼€å§‹è®­ç»ƒå®ä¾‹åˆ†å‰²æ¨¡å‹...")
    model.train(
        data=args.data,  # æ•°æ®é›†é…ç½®æ–‡ä»¶
        epochs=args.epochs,  # è®­ç»ƒè½®æ¬¡
        imgsz=args.imgsz,  # è¾“å…¥å›¾ç‰‡å°ºå¯¸
        batch=args.batch,  # æ‰¹æ¬¡å¤§å°
        device=args.device,  # è®­ç»ƒè®¾å¤‡
        lr0=args.lr0,  # åˆå§‹å­¦ä¹ ç‡
        project=args.project,  # ç»“æœä¿å­˜æ ¹ç›®å½•
        name=args.name,  # æœ¬æ¬¡è®­ç»ƒæ–‡ä»¶å¤¹åç§°
        pretrained=True,  # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ˆé»˜è®¤å¼€å¯ï¼‰
        augment=True,  # å¯ç”¨æ•°æ®å¢å¼º
        mask_ratio=4,  # æ©ç ç¼©æ”¾æ¯”ä¾‹ï¼ˆå½±å“åˆ†å‰²ç²¾åº¦ï¼‰
        save=True,  # ä¿å­˜è®­ç»ƒç»“æœ
        val=True,  # è®­ç»ƒä¸­è‡ªåŠ¨éªŒè¯ï¼ˆé»˜è®¤å¼€å¯ï¼‰
        cache=True,
        amp=False,  # å…³é—­AMPï¼Œé¿å…è§¦å‘æ£€æŸ¥ï¼ˆåç»­å¯å†å¼€å¯ï¼‰
    )

    # 4. è®­ç»ƒå®Œæˆååœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    print("è®­ç»ƒå®Œæˆï¼Œå¼€å§‹åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°...")
    metrics = model.val()  # è¯„ä¼°ç»“æœåŒ…å«APã€mask APç­‰æŒ‡æ ‡
    print(f"éªŒè¯é›†æŒ‡æ ‡: {metrics}")

    # 5. å¯¹ç¤ºä¾‹å›¾ç‰‡è¿›è¡Œæ¨ç†ï¼ˆå¯é€‰ï¼‰
    # æ‰¾ä¸€å¼ éªŒè¯é›†å›¾ç‰‡ä½œä¸ºç¤ºä¾‹
    val_img_dir = os.path.join(os.path.dirname(args.data), "images", "val")
    if os.path.exists(val_img_dir) and len(os.listdir(val_img_dir)) > 0:
        sample_img = os.path.join(val_img_dir, os.listdir(val_img_dir)[0])
        print(f"å¯¹ç¤ºä¾‹å›¾ç‰‡æ¨ç†: {sample_img}")
        pred = model(sample_img)
        # ä¿å­˜æ¨ç†ç»“æœï¼ˆåŒ…å«è¾¹ç•Œæ¡†å’Œåˆ†å‰²æ©ç ï¼‰
        save_dir = os.path.join(args.project, args.name, "predictions")
        os.makedirs(save_dir, exist_ok=True)
        pred[0].save(os.path.join(save_dir, "sample_pred.jpg"))
        print(f"æ¨ç†ç»“æœå·²ä¿å­˜è‡³: {save_dir}")


if __name__ == "__main__":
    args = parse_args()
    train_segmentation(args)
