# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import os

import cv2

from ultralytics import YOLO


def detect_keypoints(video_path, output_path, conf=0.3):
    """
    ç”¨YOLOå…³é”®ç‚¹æ£€æµ‹æ¨¡å‹æ£€æµ‹è§†é¢‘ä¸­è¡Œäººçš„å…³é”®ç‚¹å¹¶ä¿å­˜ç»“æœ
    :param video_path: è¾“å…¥è§†é¢‘è·¯å¾„
    :param output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
    :param conf: ç½®ä¿¡åº¦é˜ˆå€¼.
    """
    # åŠ è½½YOLOv8å…³é”®ç‚¹æ£€æµ‹æ¨¡å‹ï¼ˆé¢„è®­ç»ƒçš„å§¿æ€ä¼°è®¡æ¨¡å‹ï¼‰
    model = YOLO("yolov8n-pose.pt")  # "n"ä»£è¡¨è½»é‡åŒ–ï¼Œ"pose"è¡¨ç¤ºå…³é”®ç‚¹æ£€æµ‹æ¨¡å‹

    # æ‰“å¼€è¾“å…¥è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"é”™è¯¯ï¼šæ— æ³•æ‰“å¼€è§†é¢‘ {video_path}")
        return

    # è·å–è§†é¢‘å‚æ•°ï¼ˆç”¨äºä¿å­˜è¾“å‡ºï¼‰
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    print(f"å¼€å§‹å¤„ç†è§†é¢‘ï¼š{os.path.basename(video_path)}")
    frame_count = 0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # è·å–æ€»å¸§æ•°

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break  # è§†é¢‘å¤„ç†å®Œæ¯•

        # æ£€æµ‹å…³é”®ç‚¹ï¼ˆä»…æ£€æµ‹è¡Œäººï¼Œç±»åˆ«IDä¸º0ï¼‰
        results = model.predict(
            frame,
            conf=conf,
            classes=[0],  # ä»…æ£€æµ‹è¡Œäºº
            verbose=False,  # å…³é—­å®æ—¶æ—¥å¿—
        )

        # ç»˜åˆ¶æ£€æµ‹ç»“æœï¼šåŒ…å«è¾¹ç•Œæ¡†ã€å…³é”®ç‚¹å’Œéª¨æ¶è¿æ¥
        annotated_frame = results[0].plot(
            boxes=True,  # æ˜¾ç¤ºè¾¹ç•Œæ¡†
            labels=True,  # æ˜¾ç¤ºæ ‡ç­¾ï¼ˆperson + ç½®ä¿¡åº¦ï¼‰
            kpt_radius=3,  # å…³é”®ç‚¹åŠå¾„
            kpt_line=True,  # æ˜¾ç¤ºå…³é”®ç‚¹ä¹‹é—´çš„è¿æ¥ï¼ˆéª¨æ¶ï¼‰
        )

        # ä¿å­˜å¸§åˆ°è¾“å‡ºè§†é¢‘
        out.write(annotated_frame)

        # æ˜¾ç¤ºè¿›åº¦
        frame_count += 1
        if frame_count % 10 == 0:
            progress = (frame_count / total_frames) * 100
            print(f"å¤„ç†è¿›åº¦ï¼š{frame_count}/{total_frames} å¸§ ({progress:.1f}%)")

        # å®æ—¶æ˜¾ç¤ºï¼ˆæŒ‰ESCé”®é€€å‡ºï¼‰
        # cv2.imshow("YOLOv8 Keypoint Detection", annotated_frame)
        # if cv2.waitKey(1) & 0xFF == 27:
        #     break

    # é‡Šæ”¾èµ„æº
    cap.release()
    out.release()
    # cv2.destroyAllWindows()
    print(f"å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜è‡³ï¼š{output_path}\n")


# ---------------------- è¿è¡Œå…³é”®ç‚¹æ£€æµ‹ ----------------------
if __name__ == "__main__":
    # è¾“å…¥è§†é¢‘è·¯å¾„
    input_video = r"D:\Min\Projects\VSCodeProjects\ultralytics-main\data\vedio\vedio (2).mp4"
    # è¾“å‡ºè§†é¢‘è·¯å¾„
    output_video = r"D:\Min\Projects\VSCodeProjects\ultralytics-main\results\vedioï¼ˆ2ï¼‰_keypoints.mp4"

    # è¿è¡Œå…³é”®ç‚¹æ£€æµ‹
    detect_keypoints(
        video_path=input_video,
        output_path=output_video,
        conf=0.4,  # ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¯æ ¹æ®æ•ˆæœè°ƒæ•´
    )
