# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

import os
import random
import shutil


def split_dataset(raw_data_root, output_root, train_ratio=0.8, img_extensions=(".jpg", ".jpeg", ".png", ".bmp")):
    """é€šç”¨æ•°æ®é›†åˆ’åˆ†ï¼šå°†æ‰€æœ‰å›¾ç‰‡æŒ‰å…¶ç›´æ¥çˆ¶æ–‡ä»¶å¤¹ï¼ˆç±»åˆ«åï¼‰åˆ’åˆ†åˆ°train/val.

    å‚æ•°:
        raw_data_root: åŸå§‹æ•°æ®æ ¹ç›®å½•ï¼ˆæ‰€æœ‰å›¾ç‰‡çš„ä¸Šå±‚ç›®å½•ï¼‰
        output_root: è¾“å‡ºYOLOæ ¼å¼æ•°æ®é›†ç›®å½•
        train_ratio: è®­ç»ƒé›†å æ¯”ï¼ˆé»˜è®¤0.8ï¼‰
        img_extensions: å›¾ç‰‡æ–‡ä»¶æ‰©å±•å
    """
    # 1. æ”¶é›†æ‰€æœ‰å›¾ç‰‡è·¯å¾„åŠå¯¹åº”çš„ç±»åˆ«ï¼ˆç±»åˆ« = å›¾ç‰‡æ‰€åœ¨çš„ç›´æ¥æ–‡ä»¶å¤¹åç§°ï¼‰
    all_images = []  # å­˜å‚¨å…ƒç»„ (å›¾ç‰‡è·¯å¾„, ç±»åˆ«å)

    # é€’å½’éå†æ‰€æœ‰ç›®å½•ï¼Œå¯»æ‰¾å›¾ç‰‡æ–‡ä»¶
    for root, dirs, files in os.walk(raw_data_root):
        for file in files:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå›¾ç‰‡
            if file.lower().endswith(img_extensions):
                img_path = os.path.join(root, file)
                cls_name = os.path.basename(root)  # ç±»åˆ«å = ç›´æ¥çˆ¶æ–‡ä»¶å¤¹åç§°
                all_images.append((img_path, cls_name))

    if not all_images:
        print("æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥åŸå§‹æ•°æ®è·¯å¾„ï¼")
        return

    # 2. æŒ‰ç±»åˆ«åˆ†ç»„ï¼ˆç¡®ä¿æ¯ä¸ªç±»åˆ«çš„æ•°æ®å•ç‹¬åˆ’åˆ†ï¼‰
    from collections import defaultdict

    cls_to_images = defaultdict(list)
    for img_path, cls_name in all_images:
        cls_to_images[cls_name].append(img_path)

    # 3. åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„ï¼ˆtrain/ç±»åˆ«åã€val/ç±»åˆ«åï¼‰
    train_root = os.path.join(output_root, "train")
    val_root = os.path.join(output_root, "val")
    os.makedirs(train_root, exist_ok=True)
    os.makedirs(val_root, exist_ok=True)

    # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºæ–‡ä»¶å¤¹
    for cls_name in cls_to_images.keys():
        os.makedirs(os.path.join(train_root, cls_name), exist_ok=True)
        os.makedirs(os.path.join(val_root, cls_name), exist_ok=True)

    # 4. åˆ’åˆ†å¹¶å¤åˆ¶å›¾ç‰‡ï¼ˆæŒ‰ç±»åˆ«æ‰“ä¹±ååˆ’åˆ†ï¼‰
    train_count = 0
    val_count = 0
    for cls_name, img_paths in cls_to_images.items():
        # æ‰“ä¹±åŒä¸€ç±»åˆ«çš„å›¾ç‰‡é¡ºåº
        random.shuffle(img_paths)
        # è®¡ç®—åˆ’åˆ†ç‚¹
        split_idx = int(len(img_paths) * train_ratio)
        train_imgs = img_paths[:split_idx]
        val_imgs = img_paths[split_idx:]

        # å¤åˆ¶åˆ°è®­ç»ƒé›†
        for img_path in train_imgs:
            dst_filename = os.path.basename(img_path)
            dst_path = os.path.join(train_root, cls_name, dst_filename)
            # å¤„ç†åŒåæ–‡ä»¶ï¼ˆé¿å…è¦†ç›–ï¼Œæ·»åŠ åç¼€ï¼‰
            if os.path.exists(dst_path):
                name, ext = os.path.splitext(dst_filename)
                dst_path = os.path.join(train_root, cls_name, f"{name}_dup{ext}")
            shutil.copy2(img_path, dst_path)  # ä¿ç•™å…ƒæ•°æ®
            train_count += 1

        # å¤åˆ¶åˆ°éªŒè¯é›†
        for img_path in val_imgs:
            dst_filename = os.path.basename(img_path)
            dst_path = os.path.join(val_root, cls_name, dst_filename)
            if os.path.exists(dst_path):
                name, ext = os.path.splitext(dst_filename)
                dst_path = os.path.join(val_root, cls_name, f"{name}_dup{ext}")
            shutil.copy2(img_path, dst_path)
            val_count += 1

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print("æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼")
    print(f"æ€»ç±»åˆ«æ•°: {len(cls_to_images)}")
    print(f"æ€»å›¾ç‰‡æ•°: {len(all_images)}")
    print(f"è®­ç»ƒé›†: {train_count} å¼ ï¼ˆ{train_ratio * 100}%ï¼‰")
    print(f"éªŒè¯é›†: {val_count} å¼ ï¼ˆ{(1 - train_ratio) * 100}%ï¼‰")
    print(f"è¾“å‡ºè·¯å¾„: {output_root}")


if __name__ == "__main__":
    # -------------------------- é…ç½®å‚æ•° --------------------------
    raw_data_root = r"D:\Min\Projects\VSCodeProjects\dataset\cls_dataset3\data"  # æ›¿æ¢ä¸ºä½ çš„åŸå§‹æ•°æ®æ ¹ç›®å½•
    output_root = (
        r"D:\Min\Projects\VSCodeProjects\dataset\cls_dataset3\data\yolo_cls_dataset"  # è¾“å‡ºçš„YOLOæ ¼å¼æ•°æ®é›†ç›®å½•
    )
    train_ratio = 0.8  # è®­ç»ƒé›†å æ¯”ï¼ˆå¯è°ƒæ•´ä¸º0.7ã€0.9ç­‰ï¼‰
    # --------------------------------------------------------------

    split_dataset(raw_data_root=raw_data_root, output_root=output_root, train_ratio=train_ratio)
