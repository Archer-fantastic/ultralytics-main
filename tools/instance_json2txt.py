# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

# import os
# import json
# import shutil
# import random
# from tqdm import tqdm

# def labelme_to_yolo_seg(raw_dir, output_dir, train_ratio=0.8):
#     """
#     å°†LabelMeæ ¼å¼çš„å®ä¾‹åˆ†å‰²æ•°æ®è½¬æ¢ä¸ºYOLOæ ¼å¼

#     å‚æ•°:
#         raw_dir: åŸå§‹æ•°æ®ç›®å½•ï¼ˆåŒ…å«.jpgå’Œå¯¹åº”çš„.jsonæ–‡ä»¶ï¼‰
#         output_dir: è¾“å‡ºYOLOæ ¼å¼æ•°æ®çš„ç›®å½•
#         train_ratio: è®­ç»ƒé›†å æ¯”
#     """
#     # 1. åˆå§‹åŒ–ç›®å½•
#     img_train_dir = os.path.join(output_dir, 'images', 'train')
#     img_val_dir = os.path.join(output_dir, 'images', 'val')
#     lbl_train_dir = os.path.join(output_dir, 'labels', 'train')
#     lbl_val_dir = os.path.join(output_dir, 'labels', 'val')

#     os.makedirs(img_train_dir, exist_ok=True)
#     os.makedirs(img_val_dir, exist_ok=True)
#     os.makedirs(lbl_train_dir, exist_ok=True)
#     os.makedirs(lbl_val_dir, exist_ok=True)

#     # 2. æ”¶é›†æ‰€æœ‰å›¾ç‰‡å’Œå¯¹åº”çš„JSONæ–‡ä»¶
#     image_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
#     all_images = [f for f in os.listdir(raw_dir) if f.lower().endswith(image_extensions)]
#     if not all_images:
#         print("æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥åŸå§‹ç›®å½•ï¼")
#         return

#     # 3. è·å–æ‰€æœ‰ç±»åˆ«å¹¶åˆ†é…IDï¼ˆæŒ‰å­—æ¯é¡ºåºæ’åºï¼Œç¡®ä¿IDå›ºå®šï¼‰
#     classes = set()
#     for img_name in all_images:
#         json_name = os.path.splitext(img_name)[0] + '.json'
#         json_path = os.path.join(raw_dir, json_name)
#         if not os.path.exists(json_path):
#             print(f"è­¦å‘Šï¼š{img_name} ç¼ºå°‘å¯¹åº”æ ‡æ³¨æ–‡ä»¶ {json_name}ï¼Œå·²è·³è¿‡")
#             continue
#         with open(json_path, 'r', encoding='utf-8') as f:
#             data = json.load(f)
#         for shape in data.get('shapes', []):
#             classes.add(shape['label'])
#     class_list = sorted(classes)  # æ’åºç¡®ä¿ç±»åˆ«IDå›ºå®š
#     class_id = {cls: i for i, cls in enumerate(class_list)}
#     print(f"æ£€æµ‹åˆ° {len(class_list)} ä¸ªç±»åˆ«ï¼š{class_list}")

#     # 4. åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
#     random.shuffle(all_images)
#     split_idx = int(len(all_images) * train_ratio)
#     train_images = all_images[:split_idx]
#     val_images = all_images[split_idx:]

#     # 5. è½¬æ¢å¹¶å¤åˆ¶æ–‡ä»¶
#     def process_images(images, img_dst, lbl_dst):
#         for img_name in tqdm(images, desc=f"å¤„ç†{os.path.basename(img_dst)}"):
#             img_path = os.path.join(raw_dir, img_name)
#             json_name = os.path.splitext(img_name)[0] + '.json'
#             json_path = os.path.join(raw_dir, json_name)

#             # è·³è¿‡æ— æ ‡æ³¨çš„å›¾ç‰‡
#             if not os.path.exists(json_path):
#                 continue

#             # å¤åˆ¶å›¾ç‰‡åˆ°ç›®æ ‡ç›®å½•
#             shutil.copy2(img_path, os.path.join(img_dst, img_name))

#             # è§£æJSONå¹¶ç”ŸæˆYOLOæ ‡æ³¨
#             with open(json_path, 'r', encoding='utf-8') as f:
#                 data = json.load(f)
#             img_h = data.get('imageHeight')
#             img_w = data.get('imageWidth')
#             if not img_h or not img_w:
#                 print(f"è­¦å‘Šï¼š{json_name} ç¼ºå°‘å›¾ç‰‡å°ºå¯¸ä¿¡æ¯ï¼Œå·²è·³è¿‡")
#                 continue

#             # ç”Ÿæˆ.txtæ ‡æ³¨æ–‡ä»¶
#             lbl_name = os.path.splitext(img_name)[0] + '.txt'
#             lbl_path = os.path.join(lbl_dst, lbl_name)
#             with open(lbl_path, 'w', encoding='utf-8') as f:
#                 for shape in data.get('shapes', []):
#                     cls = shape['label']
#                     if cls not in class_id:
#                         continue  # è·³è¿‡æœªè®°å½•çš„ç±»åˆ«
#                     points = shape['points']  # åŸå§‹åæ ‡ (x, y)ï¼Œæœªå½’ä¸€åŒ–
#                     # å½’ä¸€åŒ–åæ ‡ï¼ˆx / img_w, y / img_hï¼‰
#                     normalized = []
#                     for (x, y) in points:
#                         normalized.append(round(x / img_w, 6))  # ä¿ç•™6ä½å°æ•°
#                         normalized.append(round(y / img_h, 6))
#                     # å†™å…¥æ ¼å¼ï¼šclass_id x1 y1 x2 y2 ...
#                     f.write(f"{class_id[cls]} {' '.join(map(str, normalized))}\n")

#     # å¤„ç†è®­ç»ƒé›†å’ŒéªŒè¯é›†
#     process_images(train_images, img_train_dir, lbl_train_dir)
#     process_images(val_images, img_val_dir, lbl_val_dir)

#     # 6. ç”Ÿæˆæ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆdataset.yamlï¼‰
#     yaml_path = os.path.join(output_dir, 'dataset.yaml')
#     with open(yaml_path, 'w', encoding='utf-8') as f:
#         f.write(f"path: {output_dir}\n")
#         f.write("train: images/train\n")
#         f.write("val: images/val\n")
#         f.write(f"nc: {len(class_list)}\n")
#         f.write(f"names: {class_list}\n")

#     print(f"è½¬æ¢å®Œæˆï¼è¾“å‡ºç›®å½•ï¼š{output_dir}")
#     print(f"è®­ç»ƒé›†å›¾ç‰‡æ•°ï¼š{len(train_images)}ï¼ŒéªŒè¯é›†å›¾ç‰‡æ•°ï¼š{len(val_images)}")
#     print(f"å·²ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼š{yaml_path}")

# if __name__ == '__main__':
#     # -------------------------- é…ç½®å‚æ•° --------------------------
#     raw_dir = r'D:\Min\Projects\VSCodeProjects\dataset\instance_251017_æ¼é‡‘å±_lxm\data'  # åŸå§‹æ•°æ®ç›®å½•ï¼ˆå­˜æ”¾.jpgå’Œ.jsonï¼‰
#     output_dir = r'D:\Min\Projects\VSCodeProjects\dataset\instance_251017_æ¼é‡‘å±_lxm\yolo_instance_dataset'  # è¾“å‡ºYOLOæ ¼å¼ç›®å½•
#     train_ratio = 0.8  # è®­ç»ƒé›†å æ¯”
#     # --------------------------------------------------------------

#     labelme_to_yolo_seg(
#         raw_dir=raw_dir,
#         output_dir=output_dir,
#         train_ratio=train_ratio
#     )

import json
import os
import random
import shutil

from tqdm import tqdm


def labelme_to_yolo_seg(raw_dir, output_dir, train_ratio=0.8):
    """å°†LabelMeæ ¼å¼çš„å®ä¾‹åˆ†å‰²æ•°æ®è½¬æ¢ä¸ºYOLOæ ¼å¼ï¼ˆæ”¯æŒé€’å½’è¯»å–å­æ–‡ä»¶å¤¹ï¼‰.

    å‚æ•°:
        raw_dir: åŸå§‹æ•°æ®æ ¹ç›®å½•ï¼ˆä¼šé€’å½’éå†æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼‰
        output_dir: è¾“å‡ºYOLOæ ¼å¼æ•°æ®çš„ç›®å½•
        train_ratio: è®­ç»ƒé›†å æ¯”
    """
    # 1. åˆå§‹åŒ–è¾“å‡ºç›®å½•
    img_train_dir = os.path.join(output_dir, "images", "train")
    img_val_dir = os.path.join(output_dir, "images", "val")
    lbl_train_dir = os.path.join(output_dir, "labels", "train")
    lbl_val_dir = os.path.join(output_dir, "labels", "val")

    os.makedirs(img_train_dir, exist_ok=True)
    os.makedirs(img_val_dir, exist_ok=True)
    os.makedirs(lbl_train_dir, exist_ok=True)
    os.makedirs(lbl_val_dir, exist_ok=True)

    # 2. é€’å½’æ”¶é›†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶ï¼ˆæ”¯æŒå­æ–‡ä»¶å¤¹ï¼‰
    image_extensions = (".jpg", ".jpeg", ".png", ".bmp", ".JPG", ".PNG")
    all_images = []

    # é€’å½’éå†æ‰€æœ‰å­ç›®å½•
    for root, _, files in os.walk(raw_dir):
        for file in files:
            if file.lower().endswith(image_extensions):
                # ä¿å­˜å›¾ç‰‡çš„å®Œæ•´è·¯å¾„
                all_images.append(os.path.join(root, file))

    if not all_images:
        print("æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥åŸå§‹ç›®å½•ï¼")
        return
    print(f"å…±å‘ç° {len(all_images)} å¼ å›¾ç‰‡ï¼ˆå«å­æ–‡ä»¶å¤¹ï¼‰")

    # 3. è·å–æ‰€æœ‰ç±»åˆ«å¹¶åˆ†é…IDï¼ˆæŒ‰å­—æ¯é¡ºåºæ’åºï¼Œç¡®ä¿IDå›ºå®šï¼‰
    classes = set()
    valid_image_paths = []  # å­˜å‚¨æœ‰å¯¹åº”æ ‡æ³¨çš„å›¾ç‰‡è·¯å¾„

    for img_path in all_images:
        # ç”Ÿæˆå¯¹åº”çš„JSONè·¯å¾„ï¼ˆä¸å›¾ç‰‡åŒç›®å½•ã€åŒåç§°ï¼‰
        img_dir = os.path.dirname(img_path)
        img_name = os.path.basename(img_path)
        json_name = os.path.splitext(img_name)[0] + ".json"
        json_path = os.path.join(img_dir, json_name)

        if not os.path.exists(json_path):
            print(f"è­¦å‘Šï¼š{img_path} ç¼ºå°‘å¯¹åº”æ ‡æ³¨æ–‡ä»¶ {json_name}ï¼Œå·²è·³è¿‡")
            continue

        # è¯»å–JSONå¹¶æå–ç±»åˆ«
        try:
            with open(json_path, encoding="utf-8") as f:
                data = json.load(f)
            for shape in data.get("shapes", []):
                classes.add(shape["label"])
            valid_image_paths.append(img_path)  # åªæœ‰æœ‰æ ‡æ³¨çš„å›¾ç‰‡æ‰ä¿ç•™
        except Exception as e:
            print(f"è­¦å‘Šï¼šè§£æ {json_path} å¤±è´¥ï¼Œé”™è¯¯ï¼š{e!s}ï¼Œå·²è·³è¿‡")

    if not valid_image_paths:
        print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å¸¦æ ‡æ³¨å›¾ç‰‡ï¼Œè½¬æ¢ç»ˆæ­¢ï¼")
        return

    class_list = sorted(classes)  # æ’åºç¡®ä¿ç±»åˆ«IDå›ºå®š
    class_id = {cls: i for i, cls in enumerate(class_list)}
    print(f"æ£€æµ‹åˆ° {len(class_list)} ä¸ªç±»åˆ«ï¼š{class_list}")

    # 4. åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆåŸºäºæœ‰æ•ˆå›¾ç‰‡ï¼‰
    random.shuffle(valid_image_paths)
    split_idx = int(len(valid_image_paths) * train_ratio)
    train_images = valid_image_paths[:split_idx]
    val_images = valid_image_paths[split_idx:]

    # 5. è½¬æ¢å¹¶å¤åˆ¶æ–‡ä»¶
    def process_images(images, img_dst, lbl_dst):
        for img_path in tqdm(images, desc=f"å¤„ç†{os.path.basename(img_dst)}é›†"):
            img_name = os.path.basename(img_path)
            img_dir = os.path.dirname(img_path)
            json_name = os.path.splitext(img_name)[0] + ".json"
            json_path = os.path.join(img_dir, json_name)

            # å¤åˆ¶å›¾ç‰‡åˆ°ç›®æ ‡ç›®å½•ï¼ˆä¿ç•™åŸå§‹æ–‡ä»¶åï¼Œé¿å…å†²çªï¼‰
            shutil.copy2(img_path, os.path.join(img_dst, img_name))

            # è§£æJSONå¹¶ç”ŸæˆYOLOæ ‡æ³¨
            with open(json_path, encoding="utf-8") as f:
                data = json.load(f)
            img_h = data.get("imageHeight")
            img_w = data.get("imageWidth")
            if not img_h or not img_w:
                print(f"è­¦å‘Šï¼š{json_path} ç¼ºå°‘å›¾ç‰‡å°ºå¯¸ä¿¡æ¯ï¼Œå·²è·³è¿‡")
                continue

            # ç”Ÿæˆ.txtæ ‡æ³¨æ–‡ä»¶ï¼ˆä¸å›¾ç‰‡åŒåï¼‰
            lbl_name = os.path.splitext(img_name)[0] + ".txt"
            lbl_path = os.path.join(lbl_dst, lbl_name)
            with open(lbl_path, "w", encoding="utf-8") as f:
                for shape in data.get("shapes", []):
                    cls = shape["label"]
                    if cls not in class_id:
                        continue  # è·³è¿‡æœªè®°å½•çš„ç±»åˆ«
                    points = shape["points"]  # åŸå§‹åæ ‡ (x, y)
                    # å½’ä¸€åŒ–åæ ‡ï¼ˆx / img_w, y / img_hï¼‰
                    normalized = []
                    for x, y in points:
                        normalized.append(round(x / img_w, 6))  # ä¿ç•™6ä½å°æ•°
                        normalized.append(round(y / img_h, 6))
                    # å†™å…¥æ ¼å¼ï¼šclass_id x1 y1 x2 y2 ...
                    f.write(f"{class_id[cls]} {' '.join(map(str, normalized))}\n")

    # å¤„ç†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    process_images(train_images, img_train_dir, lbl_train_dir)
    process_images(val_images, img_val_dir, lbl_val_dir)

    # 6. ç”Ÿæˆæ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆdataset.yamlï¼‰
    yaml_path = os.path.join(output_dir, "dataset.yaml")
    with open(yaml_path, "w", encoding="utf-8") as f:
        f.write(f"path: {output_dir}\n")
        f.write("train: images/train\n")
        f.write("val: images/val\n")
        f.write(f"nc: {len(class_list)}\n")
        f.write(f"names: {class_list}\n")

    print(f"\nè½¬æ¢å®Œæˆï¼è¾“å‡ºç›®å½•ï¼š{output_dir}")
    print(f"æœ‰æ•ˆå›¾ç‰‡æ€»æ•°ï¼š{len(valid_image_paths)}")
    print(f"è®­ç»ƒé›†å›¾ç‰‡æ•°ï¼š{len(train_images)}ï¼ŒéªŒè¯é›†å›¾ç‰‡æ•°ï¼š{len(val_images)}")
    print(f"å·²ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼š{yaml_path}")


if __name__ == "__main__":
    # -------------------------- é…ç½®å‚æ•° --------------------------
    raw_dir = r"D:\Min\Projects\VSCodeProjects\dataset\instance_251017_æ¼é‡‘å±_lxm\data"  # åŸå§‹æ•°æ®æ ¹ç›®å½•
    output_dir = r"D:\Min\Projects\VSCodeProjects\dataset\instance_251017_æ¼é‡‘å±_lxm\yolo_instance_dataset"  # è¾“å‡ºç›®å½•
    train_ratio = 0.8  # è®­ç»ƒé›†å æ¯”
    # --------------------------------------------------------------

    labelme_to_yolo_seg(raw_dir=raw_dir, output_dir=output_dir, train_ratio=train_ratio)
