# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†ï¼ŒéªŒè¯é›†ï¼Œæµ‹è¯•é›†."""

import os
import random
import shutil
from pathlib import Path

from tqdm import tqdm


# åˆ›å»ºä¿å­˜æ•°æ®çš„æ–‡ä»¶å¤¹
def makedir(new_dir):
    if not os.path.exists(new_dir):
        os.makedirs(new_dir)


def split_data(img_dir, label_dir, split_dir, TEST=True, split_ratio=[0.6, 0.3, 0.1], _Random=True):
    """
    Args:
        img_dir: åŸå›¾ç‰‡æ•°æ®é›†è·¯å¾„
        label_dir: åŸyologæ ¼å¼txtæ–‡ä»¶æ•°æ®é›†è·¯å¾„
        split_dir: åˆ’åˆ†åæ•°æ®é›†ä¿å­˜è·¯å¾„
        TEST: æ˜¯å¦åˆ’åˆ†æµ‹è¯•é›† ç”¨äºå°†æ•°æ®é›†åˆ’åˆ†ä¸ºYOLOæ•°æ®é›†æ ¼å¼çš„è®­ç»ƒé›†,éªŒè¯é›†,æµ‹è¯•é›†.
    """
    random.seed(42)  # éšæœºç§å­
    # 1.ç¡®å®šåŸå›¾ç‰‡æ•°æ®é›†è·¯å¾„
    datasetimg_dir = img_dir
    # ç¡®å®šåŸlabelæ•°æ®é›†è·¯å¾„
    datasetlabel_dir = label_dir

    images_dir = os.path.join(split_dir, "images")
    labels_dir = os.path.join(split_dir, "labels")
    dir_list = [images_dir, labels_dir]
    if TEST:
        type_label = ["train", "val", "test_yes"]
    else:
        type_label = ["train", "val"]

    for i in range(len(dir_list)):
        for j in range(len(type_label)):
            makedir(os.path.join(dir_list[i], type_label[j]))

    # 3.ç¡®å®šå°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†ï¼ŒéªŒè¯é›†ï¼Œæµ‹è¯•é›†çš„æ¯”ä¾‹
    train_pct = split_ratio[0]
    valid_pct = 1 - split_ratio[0] - split_ratio[2]
    split_ratio[2]
    # 4.åˆ’åˆ†
    images = os.listdir(datasetimg_dir)
    valid_exts = (".jpg", ".jpeg", ".png")
    images = list(filter(lambda x: x.lower().endswith(valid_exts), images))
    # # å±•ç¤ºç›®æ ‡æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰çš„æ–‡ä»¶å
    # images = list(filter(lambda x: x.endswith('.jpg'), images))  # å–åˆ°æ‰€æœ‰ä»¥.txtç»“å°¾çš„yoloæ ¼å¼æ–‡ä»¶
    if _Random:
        random.shuffle(images)  # ä¹±åºè·¯å¾„
    image_count = len(images)  # è®¡ç®—å›¾ç‰‡æ•°é‡
    train_point = int(image_count * train_pct)  # 0:train_pct
    valid_point = int(image_count * (train_pct + valid_pct))  # train_pct:valid_pct
    for i in tqdm(range(image_count), total=image_count, desc="Processing files"):
        if i < train_point:  # ä¿å­˜0-train_pointçš„å›¾ç‰‡å’Œæ ‡ç­¾åˆ°è®­ç»ƒé›†
            out_dir = os.path.join(images_dir, "train")
            label_out_dir = os.path.join(labels_dir, "train")
        elif train_point <= i < valid_point:  # ä¿å­˜train_point-valid_pointçš„å›¾ç‰‡å’Œæ ‡ç­¾åˆ°éªŒè¯é›†
            out_dir = os.path.join(images_dir, "val")
            label_out_dir = os.path.join(labels_dir, "val")
        else:  # ä¿å­˜test_point-ç»“æŸçš„å›¾ç‰‡å’Œæ ‡ç­¾åˆ°æµ‹è¯•é›†
            out_dir = os.path.join(images_dir, "test")
            label_out_dir = os.path.join(labels_dir, "test")
        if not os.path.exists(out_dir):
            os.makedirs(out_dir)
        if not os.path.exists(label_out_dir):
            os.makedirs(label_out_dir)

        last_dot_index = images[i].rfind(".")
        image_name = images[i][:last_dot_index]

        label_target_path = os.path.join(label_out_dir, image_name + ".txt")  # æŒ‡å®šç›®æ ‡ä¿å­˜è·¯å¾„
        label_src_path = os.path.join(datasetlabel_dir, image_name + ".txt")  # æŒ‡å®šç›®æ ‡åŸæ–‡ä»¶è·¯å¾„
        img_target_path = os.path.join(out_dir, images[i])  # æŒ‡å®šç›®æ ‡ä¿å­˜è·¯å¾„
        img_src_path = os.path.join(datasetimg_dir, images[i])  # æŒ‡å®šç›®æ ‡åŸå›¾åƒè·¯å¾„

        if os.path.exists(img_target_path):
            img_target_path = os.path.join(out_dir, image_name + "_new" + images[i][last_dot_index + 1 :])
            label_target_path = os.path.join(label_out_dir, image_name + "_new.txt")  # æŒ‡å®šç›®æ ‡ä¿å­˜è·¯å¾„

        if os.path.exists(label_src_path) and os.path.exists(img_src_path):
            shutil.copy(label_src_path, label_target_path)  # å¤åˆ¶txt
            shutil.copy(img_src_path, img_target_path)  # å¤åˆ¶å›¾ç‰‡

    print(f"train:{train_point}, val:{valid_point - train_point}, test_yes:{image_count - valid_point}")


def split_dataset_by_dir(dir_path, dataset_path, TEST=False, split_ratio=[0.6, 0.3, 0.1], _Random=True):
    paths = list(Path(dir_path).rglob("*/**"))
    # print(paths)
    for p in paths:
        if str(p).count("images_yolo_txt") + str(p).count("crop") > 0:
            continue
        print("processing:", p)

        label_dir = rf"{p!s}_yolo_txt"
        split_data(p, label_dir, dataset_path, TEST=TEST, split_ratio=split_ratio, _Random=_Random)
        print(p.name + "å·²æ‹·è´å®Œæˆ")


def split_one_dataset(img_dir, dataset_path, TEST=False, split_ratio=[0.6, 0.3, 0.1], _Random=True):
    label_dir = rf"{img_dir}_yolo_txt"
    split_data(img_dir, label_dir, dataset_path, TEST=TEST, split_ratio=split_ratio, _Random=_Random)


if __name__ == "__main__":
    # split_dataset_by_dir(r"E:\Dataset\02.æœ¬ç”°äº”å‚\å‰æ‚¬å·¥ä½\20250301_S33Z_åˆ†å›¾\S33Z\å…¶å®ƒç±»",
    #                      r"U:\disk1\01.Datasets\05.lxm\04.å¹¿æ±½æœ¬ç”°äº”å‚\å…¶å®ƒç±»V1",
    #                      TEST=False,split_ratio=[0.6,0.4,0],_Random=True)
    split_one_dataset(
        r"D:\Projects\ultralytics-main\data\mask\images",
        r"D:\Projects\ultralytics-main\data\mask_yolo",
        split_ratio=[0.6, 0.3, 0.1],
    )
